}
mean(X)
mean(Th)
3/7
10/30
X1 = rbeta(5000, a+10,n1+b-10)
mean(X1)
a1 = a + 10 ; b1 = n1+b-10
X2 = rbeta(5000, a1 + 20,b1 + 50 -20)
mean(X2)
mean(Th)
TH
mean(Th)
set.seed(12345)
library(igraph)
setwd("/Users/wangevan/Google Drive/UMN MSBA/Spring 2018/Simulation/DataFiles (2)")
friends <-  read.csv("friends.csv")
g3 <- graph_from_data_frame(friends,directed =  FALSE)
mean_distance(g3)
plot(g3)
g_list <- vector("list",1000)
for(i in 1:1000){
g_list[[i]] <- erdos.renyi.game(n = gorder(g3),
p.or.m = mean_distance(g3),
type = "gnm")
}
g3.apls <- unlist(lapply(g_list, mean_distance, directed =  FALSE))
hist(g3.apls , breaks = 20, xlim = c(1,4))
hist(g3.apls , breaks = 20, xlim = c(1,4))
abline(v = mean_distance(g3), col = "red", lty = 3, lwd = 2)
sum(g3.apls < mean_distance(g3, directed = FALSE))/1000
1/32
1/64
1/16
250  + 250 + 250 + 186 + 128 + 50
250 + 250 + 125 + 62 + 32 + 10
729 / 1114
sqrt(70^2 + 40*sqrt(2))
40*sqrt(2)
70^2
sqrt(70^2 + 40*sqrt(2)^2)
sqrt(70^2 + (40*sqrt(2))^2)
70/0.1
x= c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6,
8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,
11.3, 11.9)
x= c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6,
8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,
11.3, 11.9)
t.test(x-9,alternative="two.sided",conf.level=0.95)
x=c(418,421,421,422,425,427,431,434,437,439,446,447,448,453,454,463,465)
y=c(429,430,430,431,36,437,440,441,445,446,447)
test2<-t.test(x,y,alternative="two.sided",mu=0,var.equal=F,conf.level=0.95)
xbar = 14.6            # sample mean
mu0 = 15.4             # hypothesized value
s = 2.5                # sample standard deviation
n = 35                 # sample size
t = (xbar - mu0)/(s/sqrt(n))
t                      # test statistic
alpha = .05
t.half.alpha = qt(1−alpha/2, df=n−1)
c(−t.half.alpha, t.half.alpha)
alpha = .05
t.half.alpha = qt(1 - alpha/2, df=n - 1)
c( - t.half.alpha, t.half.alpha)
qt(1 - alpha/2, df=n - 1)
pval = 2 ∗ pt(t, df=n−1)
pval = 2 ∗ pt(t, df=n - 1)
pval = 2 * pt(t, df=n - 1)
2 * pt(t, df=n - 1)
pbar = 12/20           # sample proportion
p0 = .5                # hypothesized value
n = 20                 # sample size
z = (pbar - p0)/sqrt(p0 * (1 - p0)/n)
z                      # test statistic
alpha = .05
z.half.alpha = qnorm(1 - alpha/2)
c(−z.half.alpha, z.half.alpha)
alpha = .05
z.half.alpha = qnorm(1 - alpha/2)
c(- z.half.alpha, z.half.alpha)
prop.test(12, 20, p=0.5, correct=FALSE)
?prop.test
alpha = .05
z.alpha = qnorm(1 - alpha)
z.alpha
alpha = .05
z.half.alpha = qnorm(1 - alpha/2)
c(- z.half.alpha, z.half.alpha)
prop.test(30, 214, p=.12, alt="greater", correct=FALSE)
dbinom(4, size=12, prob=0.2)
pbinom(4, size=12, prob=0.2)
ppois(16, lambda=12, lower=FALSE)
runif(10, min=1, max=3)
pexp(2, rate=1/3)
x = runif(10, min=1, max=3)
plot(x)
x = runif(500, min=1, max=3)
plot(density(x))
x = runif(5000, min=1, max=3)
plot(density(x))
qt(c(.025, .975), df=5)   # 5 degrees of freedom
e
exp()
exp(1)
exp(0)
exp(1)
factor(1)
factorial(2)
factorial(3)
factorial(5)
library(MASS)
library(MASS)
mean(height.survey, na.rm=TRUE)  #skip NA
height.response = na.omit(survey$Height)
n = length(height.response)
sigma = 9.48
sem = sigma/sqrt(n); sem
mean(height.survey, na.rm=TRUE)
library(MASS)
#skip NA
height.response = na.omit(survey$Height)
n = length(height.response)
sigma = 9.48
sem = sigma/sqrt(n); sem
E = qnorm(.975) * sem; E
xbar = mean(height.response)
xbar + c(−E, E)
qnorm(.975)
E = qnorm(.975) * sem; E # Margin Error
xbar = mean(height.response)
xbar + c( - E, E)
s = sd(height.response)
SE = s/sqrt(n); SE
E = qt(.975, df=n - 1) * SE; E
s = sd(height.response)
SE = s/sqrt(n); SE
E = qt(.975, df=n - 1) * SE; E
t.test(height.response)
zstar = qnorm(.975)
sigma = 9.48
E = 1.2
zstar^2 ∗ sigma^2/ E^2
zstar = qnorm(.975)
sigma = 9.48
E = 1.2
zstar^2 * sigma^2/ E^2
n = 35                # sample size
s = 2.5               # sample standard deviation
SE = s/sqrt(n); SE
alpha = .05           # significance level
mu0 = 15.4            # hypothetical mean
I = c(alpha/2, 1-alpha/2)
q = mu0 + qt(I, df=n-1) * SE; q
diff(p)
mu = 15.1             # assumed actual mean
p = pt((q - mu)/SE, df=n-1); p #  compute the lower tail probabilities of both end points.
#the probability of type II error is the probability between the two end points.
diff(p)
```
q
qt(I, df=n-1)
I = c(alpha/2, 1-alpha/2)
I
library(MASS)
L = mtcars$am == 0
mpg.auto = mtcars[L,]$mpg
mpg.manual = mtcars[!L,]$mpg
library(MASS)
L = mtcars$am == 0
mpg.auto = mtcars[L,]$mpg
mpg.manual = mtcars[!L,]$mpg
t.test(mpg.auto, mpg.manual)
t.test(mpg ~ am, data=mtcars)
library(MASS)
table(quine$Eth, quine$Sex)
prop.test(table(quine$Eth, quine$Sex), correct=FALSE)
smoke.freq = table(survey$Smoke)
smoke.freq = table(survey$Smoke)
smoke.prob = c(.045, .795, .085, .075)
smoke.freq = table(survey$Smoke)
smoke.prob = c(.045, .795, .085, .075)
chisq.test(smoke.freq, p=smoke.prob)
tbl = table(survey$Smoke, survey$Exer)
chisq.test(tbl)
read.table("/Users/wangevan/Google Drive/UMN MSBA/JOB/table1.txt")
read.table("/Users/wangevan/Google Drive/UMN MSBA/JOB/table1.txt",header = TRUE)
x = read.table("/Users/wangevan/Google Drive/UMN MSBA/JOB/table1.txt",header = TRUE)
anova <- read.csv("~/Google Drive/UMN MSBA/JOB/anova.csv")
View(anova)
#read table 1
a = aov(Expression~Subtype, data=x)
summary(a)
#read table 1
a = aov(Expression~Subtype, data=anova)
summary(a)
# A sign test is used to decide whether a binomial distribution has the equal chance of success and failure.
binom.test(5, 18)
# A sign test is used to decide whether a binomial distribution has the equal chance of success and failure.
binom.test(5, 18)
# Wilcoxon Signed-Rank Test - decide whether the corresponding data population distributions are identical
wilcox.test(immer$Y1, immer$Y2, paired=TRUE)
# A sign test is used to decide whether a binomial distribution has the equal chance of success and failure.
binom.test(5, 18)
# Wilcoxon Signed-Rank Test - decide whether the corresponding data population distributions are identical
wilcox.test(immer$Y1, immer$Y2, paired=TRUE)
# Mann-Whitney-Wilcoxon Test - they come from distinct populations and the samples do not affect each other.
wilcox.test(mpg ~ am, data=mtcars)
# A sign test is used to decide whether a binomial distribution has the equal chance of success and failure.
binom.test(5, 18)
# Wilcoxon Signed-Rank Test - decide whether the corresponding data population distributions are identical
wilcox.test(immer$Y1, immer$Y2, paired=TRUE)
# Mann-Whitney-Wilcoxon Test - they come from distinct populations and the samples do not affect each other.
wilcox.test(mpg ~ am, data=mtcars)
#Kruskal-Wallis Test -  are independent if they come from unrelated populations and the samples do not affect each other.
kruskal.test(Ozone ~ Month, data = airquality)
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
help(summary.lm)
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.res = resid(eruption.lm)
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.res = resid(eruption.lm)
plot(faithful$waiting, eruption.res,
+     ylab="Residuals", xlab="Waiting Time",
+     main="Old Faithful Eruptions")
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.res = resid(eruption.lm)
plot(faithful$waiting, eruption.res,
ylab="Residuals", xlab="Waiting Time",      main="Old Faithful Eruptions")
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.res = resid(eruption.lm)
plot(faithful$waiting, eruption.res,
ylab="Residuals", xlab="Waiting Time",      main="Old Faithful Eruptions")
abline(0, 0)
eruption.lm = lm(eruptions ~ waiting, data=faithful)
summary(eruption.lm)$r.squared
newdata = data.frame(waiting=80)
predict(eruption.lm, newdata, interval="confidence")
eruption.res = resid(eruption.lm)
plot(faithful$waiting, eruption.res,
ylab="Residuals", xlab="Waiting Time",      main="Old Faithful Eruptions")
abline(0, 0)
## QQPLOT
eruption.stdres = rstandard(eruption.lm)
qqnorm(eruption.stdres,
ylab="Standardized Residuals",
xlab="Normal Scores",
main="Old Faithful Eruptions")
?qqnorm
am.glm = glm(formula=am ~ hp + wt,
data=mtcars,
family=binomial)
am.glm = glm(formula=am ~ hp + wt,
data=mtcars,
family=binomial)
summary(am.glm)
0.9^2 / (1-0.1^2)
0.8^2 / (1-0.2^2)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/msleep_ggplot2.csv"
filename <- "msleep_ggplot2.csv"
if (!file.exists(filename)) download(url,filename)
msleep <- read.csv("msleep_ggplot2.csv")
head(msleep)
install.packages("downloader")
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/msleep_ggplot2.csv"
filename <- "msleep_ggplot2.csv"
if (!file.exists(filename)) download(url,filename)
msleep <- read.csv("msleep_ggplot2.csv")
head(msleep)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
#
msleep %>%
select(name, sleep_total) %>%
head
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
#
msleep %>%
select(name, sleep_total) %>%
head
#
msleep %>% arrange(order) %>% head
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
#
msleep %>%
select(name, sleep_total) %>%
head
#
msleep %>% arrange(order) %>% head
#
msleep %>%
select(name, order, sleep_total) %>%
arrange(order, sleep_total) %>%
head
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
#
msleep %>%
select(name, sleep_total) %>%
head
#
msleep %>% arrange(order) %>% head
#
msleep %>%
select(name, order, sleep_total) %>%
arrange(order, sleep_total) %>%
head
#
msleep %>%
select(name, order, sleep_total) %>%
arrange(order, sleep_total) %>%
filter(sleep_total >= 16)
library(dplyr)
sleepData <- select(msleep, name, sleep_total)
head(sleepData)
#
filter(msleep, sleep_total >= 16)
#
filter(msleep, sleep_total >= 16, bodywt >= 1)
#
filter(msleep, order %in% c("Perissodactyla", "Primates"))
#
msleep %>%
select(name, sleep_total) %>%
head
#
msleep %>% arrange(order) %>% head
#
msleep %>%
select(name, order, sleep_total) %>%
arrange(order, sleep_total) %>%
head
#
msleep %>%
select(name, order, sleep_total) %>%
arrange(order, sleep_total) %>%
filter(sleep_total >= 16)
#
msleep %>%
mutate(rem_proportion = sleep_rem / sleep_total) %>%
head
msleep %>%
mutate(rem_proportion = sleep_rem / sleep_total,
bodywt_grams = bodywt * 1000) %>%
head
#
msleep %>%
summarise(avg_sleep = mean(sleep_total))
#
msleep %>%
group_by(order) %>%
summarise(avg_sleep = mean(sleep_total),
min_sleep = min(sleep_total),
max_sleep = max(sleep_total),
total = n())
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
## view the first few rows of the data
head(mydata)
xtabs(~admit + rank, data = mydata)
mydata$rank <- factor(mydata$rank)
mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
am.glm = glm(formula=am ~ hp + wt,
data=mtcars,
family=binomial)
summary(am.glm)
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
## view the first few rows of the data
head(mydata)
xtabs(~admit + rank, data = mydata)
mydata$rank <- factor(mydata$rank)
mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
summary(mylogit)
exp(coef(mylogit))
exp(cbind(OR = coef(mylogit), confint(mylogit)))
library(tidyverse)
library(broom)
theme_set(theme_classic())
# Load the data
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
plot(model, which = 4, id.n = 3)
car::vif(model)
pnorm(27.4, mean=50, sd=20)
pnorm(27.4, 50, 20)
mat <- matrix(c(0.95,0.03,0.05,0.97), nrow=2)
mat
mat <- matrix(c(0.95,0.05,0.03,0.97), nrow=2)
mat
0.95*19
for(i in 1:20){
mat = mat %*% mat
}
mat
3/8
0.95 * 3/8 + 0.03 * 5/8
exp(0)
1/3109
1/3002
1/2975
1/2955
zstar = qnorm(.975)
qnorm(.95)
zstar = qnorm(.95)
p = 0.5
E = 0.05
zstar^2 ∗ p ∗ (1−p) / E^2
zstar^2 * p * (1−p) / E^2
zstar = qnorm(.95)
p = 0.5
E = 0.05
zstar^2 * p * (1 - p) / E^2
ppois(16, lambda=12)
ppois(16, lambda=12, lower=FALSE)
ppois(16, lambda=2995)
ppois(1, lambda=2995)
factorial(365)
25104128675558732292929443748812027705165520269876079766872595193901106138220937419666018009000254169376172314360982328660708071123369979853445367910653872383599704355532740937678091491429440864316046925074510134847025546014098005907965541041195496105311886173373435145517193282760847755882291690213539123479186274701519396808504940722607033001246328398800550487427999876690416973437861078185344667966871511049653888130136836199010529180056125844549488648617682915826347564148990984138067809999604687488146734837340699359838791124995957584538873616661533093253551256845056046388738129702951381151861413688922986510005440943943014699244112555755279140760492764253740250410391056421979003289600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 * 0.9
